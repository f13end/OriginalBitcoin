<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 
<!-- Mirrored from listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/006937.html by HTTrack Website Copier/3.x [XR&CO'2010], Tue, 30 Aug 2011 14:46:45 GMT -->

<!-- Mirrored from diyhpl.us/~bryan/irc/bitcoin-satoshi/p2presearch-again/p2pfoundation.net/backups/p2p_research-archives/2010-January/006937.html by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 06 Dec 2018 08:57:34 GMT -->
<HEAD>
   <TITLE> [p2p-research] Transhumanism and Adorno
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:p2presearch%40listcultures.org?Subject=Re%3A%20%5Bp2p-research%5D%20Transhumanism%20and%20Adorno&In-Reply-To=%3C00163641853b901155047cbf296c%40google.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/006936.html">
   <LINK REL="Next"  HREF="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/006947.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[p2p-research] Transhumanism and Adorno</H1>
    <B>Ryan</B> 
    <A HREF="mailto:p2presearch%40listcultures.org?Subject=Re%3A%20%5Bp2p-research%5D%20Transhumanism%20and%20Adorno&In-Reply-To=%3C00163641853b901155047cbf296c%40google.com%3E"
       TITLE="[p2p-research] Transhumanism and Adorno">rlanham1963 at gmail.com
       </A><BR>
    <I>Sat Jan  9 19:06:24 CET 2010</I>
    <P><UL>
        <LI>Previous message: <A HREF="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/006936.html">[p2p-research] Everyone wants to talk about currencies
</A></li>
        <LI>Next message: <A HREF="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/006947.html">[p2p-research] Transhumanism and Adorno
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/date.html#6937">[ date ]</a>
              <a href="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/thread.html#6937">[ thread ]</a>
              <a href="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/subject.html#6937">[ subject ]</a>
              <a href="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/author.html#6937">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>  Sent to you by Ryan via Google Reader: J. Hughes Problems of
Transhumanism: The Unsustainable Autonomy of Reason via Ethical
Technology on 1/8/10

Reason is not self-legitimating. Like all Enlightenment advocates for
reason, transhumanists find that the project of Reason erodes all
premises including the superiority of reason over unreason.
Consequently transhumanists, like Enlightenment advocates in general,
need to defend our values with nonrational a prioris. Unfortunately
some transhumanists continue to advocate a na&#239;ve conception of pure
rationality as an end in itself.



The Enlightenment and Reason
Reason was the central value of the Enlightenment. Some historians see
the beginning of the Enlightenment in the early seventeenth century
&#8220;Age of Reason,&#8221; associated with the Descartes, Spinoza, Leibniz,
Hobbes, Locke, and Berkeley. Historian Dorinda Outram defined the
central claims of the Enlightenment around its appeal to reason:

Enlightenment was a desire for human affairs to be guided by
rationality rather than by faith, superstition, or revelation; a belief
in the power of human reason to change society and liberate the
individual from the restraints of custom or arbitrary authority; all
backed up by a world view increasingly validated by science rather than
by religion or tradition. (Outram, 1995: 3)

When Kant wrote his essay (1784a) &#8220;Was ist Aufkl&#228;rung&#8221; or &#8220;What is
Enlightenment?&#8221; for the Berlinische Monatschrift, he summed up the
slogan of the Enlightenment as &#8220;sapere aude&#8221; or &#8220;dare to know.&#8221; Though
divided by epistemology and theology, these thinkers attempted to
ground philosophy on uncontestable propositions such as &#8220;cogito ergo
sum.&#8221;

This thorough-going undermining of all irrational a prioris led to a
number of philosophical dead-ends, however, immediately generating a
score of post-rationalist movements. In the midst of the Enlightenment,
Jean-Jacques Rousseau valorized the primitive and decried the harmful
effects of hyper-rationalism on morality (Glendon, 1999). After all, as
Hume underlined, the Enlightenment had severed any connection between
the IS and the OUGHT. Although Kant and the utilitarians would attempt
to re-ground ethics on what appeared to be empirical observations about
human nature, they could never answer the next question: why should
ethics be grounded on observations about human nature and not something
else, like ancient religious dogmas?

Eighteenth century Romanticism was also a reaction to the overreach of
reason in its assertion of the value of aesthetic and emotional
experience. From the eighteenth century through World War Two,
movements on both the right and left turned against Enlightenment
rationalism. On the Left, the Frankfurt School writers criticized the
Enlightenment&#8217;s instrumental rationality for its complicity in
authoritarianism (Adorno and Horkheimer, 2006; Marcuse, 1964; Saul,
1992; Gray, 1995). Various strains of feminism and anti-imperialism
attacked the patriarchal and Eurocentric construction of Enlightenment
reason (Harding, 1982). These post-rationalist movements rejected the
autonomy and universality of reason because it came into conflict with
other values of the Enlightenment, such as respect for the rights of
persons and for cultural diversity. Meanwhile, theologians and
philosophers of the Right blamed communism on the totalizing logic of
the Enlightenment&#8217;s assertion of utopian reason.

In the 20th century, Enlightenment rationalism also began to question
its own first principles. One example is found in Wittgenstein&#8217;s turn
from logical positivism. The logical positivists attempted to ban from
philosophical discourse all terms and concepts without empirical
referents. Ludwig Wittgenstein, although an early and influential
advocate of this position, eventually changed his mind as he further
investigated how language actually worked. Having turned empirical
investigation on the process of reasoning itself, and attempting to
purify language of all irrationality, Wittgenstein concluded that the
goal was chimerical (Wittgenstein, 1953). Language is a series of word
games in which meanings are created only in reference to other words
and not to empirical facts. The positivist project of building a
rational philosophy from uncontestable empirical observations is
impossible.

Foucault, Derrida, and the postmodernists also represent an implosion
of Enlightenment reason. Although I believe postmodernist &#8220;criticism&#8221;
to be mostly a dead end, the essential insight is true: all claims for
Enlightenment reason are historically situated and biased by power and
position. The Enlightenment is just one historical narrative among many
and there is no rational reason to choose the Enlightenment narrative
over any other. Reason can only be argued for from metaphysical and
ethical a prioris, even if those are only such basic assumptions as &#8216;it
is good to be able to accomplish one&#8217;s intended goals.&#8217;

Most tangibly, contemporary neuroscience, also a product of
Enlightenment reason, now recognizes that reason severed from emotion
is impotent. In Damasio&#8217;s (1994) now classic studies of patients with
brain damage that severed the ties between emotion and decision-making,
the victims were incapable of making decisions. The desire to stop
deliberating and make a decision is not itself rational &#8211; it is a
product of temperament. Reason was built to serve, but is incapable of
generating its own commands.



Transhumanists and Reason
Most transhumanists argue the Enlightenment case for Reason without
ackowledging its self-undermining nature. For instance Max More&#8217;s
Extropian Principles codified &#8220;rational thinking&#8221; as one of its seven
precepts (More, 1998):

Like humanists, transhumanists favor reason, progress, and values
centered on our well being rather than on an external religious
authority. (More, 1998)

The Transhumanist FAQ defines transhumanism as the consistent
application of reason:

The intellectual and cultural movement that affirms the possibility and
desirability of fundamentally improving the human condition through
applied reason&#8230;We might not be perfect, but we can make things better
by promoting rational thinking, freedom, tolerance, democracy, and
concern for our fellow human beings&#8230; Just as we use rational means to
improve the human condition and the external world, we can also use
such means to improve ourselves, the human organism. (Humanity+, 2003)

One of the central transhumanist blogs is Less Wrong, based at Oxford
University under the aegis of transhumanist philosopher Nick Bostrom
and dedicated to &#8220;the art of refining human rationality.&#8221; A frequent
contributor there is Eliezer Yudkowsky, an auto-didact writer on
artificial intelligence and human cognitive biases who also is a
co-founder of the Singularity Institute for Artificial Intelligence.
Yudkowsky has said that one of his goals is to lead a &#8220;mass movement to
train people to be black-belt rationalists.&#8221; The Less Wrong blog
highlights Yudkowsky&#8217;s definitions of rationality and their importance
as its raison d&#8217;etre:

What Do We Mean By &#8220;Rationality&#8221;?

We mean:

1. Epistemic rationality: believing, and updating on evidence, so as to
systematically improve the correspondence between your map and the
territory. The art of obtaining beliefs that correspond to reality as
closely as possible. This correspondence is commonly termed &#8220;truth&#8221; or
&#8220;accuracy&#8221;, and we&#8217;re happy to call it that.

2. Instrumental rationality: achieving your values. Not necessarily
&#8220;your values&#8221; in the sense of being selfish values or unshared values:
&#8220;your values&#8221; means anything you care about. The art of choosing
actions that steer the future toward outcomes ranked higher in your
preferences. On LW we sometimes refer to this as &#8220;winning.&#8221;

But why should we want a map that corresponds to the territory? Where
do the values that rationality help us achieve come from? What if the
valuation of instrumental rationality in fact is an obstacle to
achieving the things we value, as the romantics claim, such as beauty,
meaning, contentment, and awe? Yudkowsky goes so far as to acknowledge
the problem in order to define it as something that is simply not to be
discussed:

&#8230; many of us will regard as controversial&#8212;at the very least&#8212;any
construal of &#8220;rationality&#8221; that makes it non-normative. For example, if
you say, &#8220;The rational belief is X, but the true belief is Y&#8221; then you
are probably using the word &#8220;rational&#8221; in a way that means something
other than what most of us have in mind&#8230; Similarly, if you find
yourself saying, &#8220;The rational thing to do is X, but the right thing to
do is Y&#8221; then you are almost certainly using one of the words
&#8220;rational&#8221; or &#8220;right&#8221; in a way that a huge chunk of readers won&#8217;t agree
with.

Fortunately for Yudkowsky, he has been ceded authority by his readers
to write off all philosophical debate about the relationship of IS and
OUGHT. But this will leave his transhumanist rationality experts
defenseless debating those with different metaphysics, or when they
face their own dark nights of the soul.

One of the central philosophical debates between bioconservatives and
transhumanists, and &#8220;bioliberals&#8221; more generally, over the last two
decades has been over the legitimacy of emotivist arguments such as
Leon Kass&#8217; (1997) &#8220;wisdom of repugnance&#8221; (Roache and Clarke, 2009). In
2003, the bioconservative Yuval Levin wrote in &#8220;The Paradox of
Conservative Bioethics&#8221; of the tragic dilemma faced by conservatives
trying to devise rational arguments in defense of irrational taboos.
Once liberal democracy forces the conservative to abandon appeals to
tradition or intuition, democratic debate naturalizes the new.

The very fact that everything must be laid out in the open in the
democratic age is destructive of the reverence that gives moral
intuition its authority. A deep moral taboo cannot simply become
another option among others, which argues its case in the market place.
Entering the market and laying out its wares takes away from its
venerated stature, and its stature is the key to its authority. By the
very fact that it becomes open to dispute&#8212;its pros and cons tallied up
and counted&#8212;the taboo slowly ceases to exist&#8230; A conservative
bioethics&#8230;is forced to proceed by pulling up its own roots, and to
begin by violating some of the very principles it seeks to defend.
(Levin, 2003)

Transhumanists and the Enlightenment face the opposite dilemma: how to
advocate for rationality in a way that avoids its potential for
self-erosion. Just as the bioconservatives cannot validate their taboos
and ethical a prioris in the public square, there is likewise no
rational reason why society should reject taboos and superstition in
favor of a transhuman future; value judgments in favor of tradition,
faith, and taboo, or in favor of progress, reason, and liberty both
stem from pre-rational premises.

Transhumanists need to acknowledge their own historical situatedness
and defend their normative and epistemological first principles as
existential choices instead of empirical absolutes somehow derived from
reason. One example of a transhumanist acknowledging the pre-rational
roots of transhumanist values is anti-aging activist and IEET Fellow
Aubrey de Grey&#8217;s 2008 essay &#8220;Reasons and methods for promoting our duty
to extend healthy life indefinitely.&#8221; De Grey directly addresses Leon
Kass&#8217; emotivist argument and turns it on its head. What, de Grey asks,
is more repugnant than sickness, aging, and death? Those arguing the
anti-aging cause, de Grey concludes, should start from these shared
intuitions and prejudices instead of starting from reasoned arguments
that presume the &#8220;objectivity of morality&#8221; and the &#8220;unreliability of
gut feelings.&#8221; When I first heard de Grey&#8217;s argument, I demurred,
thinking he had given away too much to the emotivists. But that was
simply my own fear of letting go of my superior rational ethical
viewpoint.

When I imagine the project of Reason, I think of building a house in
mid-air. I look over at the other houses floating in mid-air, the
pre-Enlightenment houses, and they are ramshackle huts of mud daub and
random flotsam, tied up with string. To get from one room to another in
our neighbors&#8217; houses, you have to crawl to the basement and then up a
laundry chute. They sit in darkened rooms with few windows, and none
that show that the house is not in fact rooted to the earth.

With the pure, lean precision of Reason we have built our houses of
Kantianism, utilitarianism, liberal democracy, and other clean
architectural marvels, Frank Lloyd Wright structures of thought with
lots of windows, and even glass floors. But most of us steadfastly
ignore the fact that, just like our neighbors, we are floating in
mid-air. Acknowledging that we are all in mid-air and don&#8217;t know how we
got aloft in the first place is damned scary, and we have repeatedly
seen people defect from our Enlightenment houses with glass floors to
our neighbors&#8217; houses of faith and dogma where they are not forced to
look down. We need to learn the courage to acknowledge that we got this
thing in the air through an act of will&#8212;that Reason is a good tool but
that our values and moral codes are not grounded in Reason&#8212;or else we
will lose many more people to the forces of irrationality in the future.



References
Adorno, T. W., and Max Horkheimer. 2002. Dialectic of Enlightenment.
Trans. Edmund Jephcott. Stanford: Stanford UP.

Berlin, Isaiah. 1998. The Proper Study of Mankind: An Anthology of
Essays. Farrar Straus Giroux.

Damasio, Antionio. 1994. Descartes&#8217; Error: Emotion, Reason, and the
Human Brain. Putnam.

de Grey, Aubrey D.N.J. 2008. Reasons and methods for promoting our duty
to extend healthy life indefinitely. Journal of Evolution and
Technology 18(1): 50-55.

Glendon, Mary Ann. 1999. Rousseau &amp; the Revolt Against Reason. First
Things 96 (October 1999): 42-47.

Gray, John. 1995. Enlightenment&#8217;s Wake: Politics and Culture at the
Close of the Modern Age. Routledge.

Harding, Sandra. 1982. Is Gender a Variable in Conceptions of
Rationality? A Survey of Issues. Dialectica 36: 226-241.

Humanity+. 2003. Transhumanist FAQ.

Kant, Immanuel. 1784. Was ist Aufkl&#228;rung. Berlinische Monatschrift
Dezember-Heft: 481-494.

Kass, Leon R. 1997. The wisdom of repugnance. The New Republic 216(22):
17-26.

Levin, Yuval. 2003. The Paradox of Conservative Bioethics. The New
Atlantis 1(1): 53-65.

Marcuse, Herbert. 1964. One-dimensional man: Studies in the ideology of
advanced industrial society. Boston: Beacon Press.

More, Max. 1998. The Extropian Principles v3. Extropy Institute.

Outram, Dorinda. 1995. The Enlightenment. Cambridge, UK: Cambridge
University Press.

_____. 2005. The Enlightenment, 2nd ed. Cambridge, UK: Cambridge
University Press.

Roache, Rebecca and Steve Clarke. 2009. Bioconservatism, Bioliberalism
and Repugnance. Monash Bioethics Review 28(1):4.1-21.

Wittgenstein, Ludwig. 1953/2001. Philosophical Investigations.
Blackwell Publishing.

Things you can do from here:
- Subscribe to Ethical Technology using Google Reader
- Get started using Google Reader to easily keep up with all your
favorite sites
-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://listcultures.org/pipermail/p2presearch_listcultures.org/attachments/20100109/49748b51/attachment-0001.html">http://listcultures.org/pipermail/p2presearch_listcultures.org/attachments/20100109/49748b51/attachment-0001.html</A>&gt;
</PRE>














<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/006936.html">[p2p-research] Everyone wants to talk about currencies
</A></li>
	<LI>Next message: <A HREF="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/006947.html">[p2p-research] Transhumanism and Adorno
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/date.html#6937">[ date ]</a>
              <a href="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/thread.html#6937">[ thread ]</a>
              <a href="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/subject.html#6937">[ subject ]</a>
              <a href="http://listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/author.html#6937">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://listcultures.org/mailman/listinfo/p2presearch_listcultures.org">More information about the p2presearch
mailing list</a><br>
</body>
<!-- Mirrored from listcultures.org/pipermail/p2presearch_listcultures.org/2010-January/006937.html by HTTrack Website Copier/3.x [XR&CO'2010], Tue, 30 Aug 2011 14:46:45 GMT -->

<!-- Mirrored from diyhpl.us/~bryan/irc/bitcoin-satoshi/p2presearch-again/p2pfoundation.net/backups/p2p_research-archives/2010-January/006937.html by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 06 Dec 2018 08:57:34 GMT -->
</html>
